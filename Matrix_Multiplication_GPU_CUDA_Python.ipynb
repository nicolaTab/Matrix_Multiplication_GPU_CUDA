{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries"
      ],
      "metadata": {
        "id": "ox75c7347fIM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "hClARf6q6mKT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numba import cuda, float32\n",
        "import math\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set block and matrix size"
      ],
      "metadata": {
        "id": "h6YhlNRWAkAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Block and matrix size\n",
        "TPB = 16\n",
        "N = 256\n"
      ],
      "metadata": {
        "id": "00ZkVEkKAYeu"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create matrices and transfer to GPU"
      ],
      "metadata": {
        "id": "1amfMQJUAlUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix creation\n",
        "A = np.random.rand(N, N).astype(np.float32)\n",
        "B = np.random.rand(N, N).astype(np.float32)\n",
        "\n",
        "# Transfer matrices to the GPU\n",
        "A_device = cuda.to_device(A)\n",
        "B_device = cuda.to_device(B)\n",
        "C_device = cuda.device_array((N, N), dtype=np.float32)  # Resultant matrix on the GPU\n"
      ],
      "metadata": {
        "id": "LdVtY80-AYhR"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numba\n",
        "from numba import cuda\n",
        "print(\"CUDA is available:\", cuda.is_available())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9FuJyjxEiRv",
        "outputId": "b2e88f19-9a22-4073-a0b9-ec537493de0b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the CUDA kernel with shared memory"
      ],
      "metadata": {
        "id": "Fsrn2NZ0AqhL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CUDA kernel with shared memory\n",
        "@cuda.jit\n",
        "def matmul_shared_kernel(A, B, C):\n",
        "    sA = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
        "    sB = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
        "\n",
        "    x, y = cuda.grid(2)\n",
        "    tx, ty = cuda.threadIdx.x, cuda.threadIdx.y\n",
        "    if x >= C.shape[0] or y >= C.shape[1]:\n",
        "        return\n",
        "\n",
        "    temp = 0.0\n",
        "    for i in range(int(A.shape[1] / TPB)):\n",
        "        sA[ty, tx] = A[x, ty + i * TPB]\n",
        "        sB[ty, tx] = B[tx + i * TPB, y]\n",
        "        cuda.syncthreads()\n",
        "        for k in range(TPB):\n",
        "            temp += sA[ty, k] * sB[k, tx]\n",
        "        cuda.syncthreads()\n",
        "    C[x, y] = temp\n"
      ],
      "metadata": {
        "id": "pnjOUNWdAYnP"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configure blocks and grids, and measure execution time"
      ],
      "metadata": {
        "id": "RHytz3f6AswB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure blocks and grids\n",
        "blockspergrid = (math.ceil(N / TPB), math.ceil(N / TPB))\n",
        "\n",
        "# Measure execution time with cuda.event\n",
        "start = cuda.event()\n",
        "end = cuda.event()\n",
        "start.record()\n",
        "\n",
        "# Execute the kernel\n",
        "matmul_shared_kernel[blockspergrid, (TPB, TPB)](A_device, B_device, C_device)\n",
        "\n",
        "end.record()\n",
        "end.synchronize()\n",
        "\n",
        "# Calculate elapsed time\n",
        "time_elapsed = cuda.event_elapsed_time(start, end)\n",
        "print(f\"Kernel execution time: {time_elapsed} ms\")\n"
      ],
      "metadata": {
        "id": "584GwIBBAYpb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2b4fa42-87f8-4532-f07f-4fd1779df7dd"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kernel execution time: 297.3147277832031 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrieve and display data from GPU"
      ],
      "metadata": {
        "id": "C14SN7-qAvnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve data from GPU for verification\n",
        "C = C_device.copy_to_host()\n",
        "print(\"Matrix multiplication result:\\n\", C)\n"
      ],
      "metadata": {
        "id": "8cDT9EtMAYrt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d98b776-fdca-48e2-c129-e61b8438c41a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix multiplication result:\n",
            " [[65.03665  65.359726 62.63055  ... 69.617645 63.310112 67.872375]\n",
            " [68.68004  67.239265 61.43986  ... 65.68339  61.150177 63.23375 ]\n",
            " [64.672676 66.36231  62.12741  ... 69.57043  63.143124 67.746185]\n",
            " ...\n",
            " [66.34234  63.369644 67.45249  ... 66.56866  69.88551  59.975952]\n",
            " [63.4768   61.443436 65.98586  ... 66.416016 70.80537  63.430073]\n",
            " [62.882126 61.226448 65.27813  ... 66.51149  72.234314 60.80983 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt the user for matrix size and shared memory usage"
      ],
      "metadata": {
        "id": "MjJSY-26AzH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt the user for matrix size and whether shared memory should be used\n",
        "N = int(input(\"Enter matrix size (N x N): \"))\n",
        "use_shared = input(\"Use shared memory? (yes/no): \").lower() == 'yes'\n",
        "TPB = 16  # Fixed block size\n",
        "\n",
        "# Matrix creation\n",
        "A = np.random.rand(N, N).astype(np.float32)\n",
        "B = np.random.rand(N, N).astype(np.float32)\n"
      ],
      "metadata": {
        "id": "EWYxq0sOAYtc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c6f72ac-e8d1-42d1-87f0-245e443b66a9"
      },
      "execution_count": 46,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter matrix size (N x N): 5000\n",
            "Use shared memory? (yes/no): yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kernel without shared memory"
      ],
      "metadata": {
        "id": "BtadT-26A16f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Kernel without shared memory\n",
        "@cuda.jit\n",
        "def matmul_kernel(A, B, C):\n",
        "    row, col = cuda.grid(2)\n",
        "    if row < C.shape[0] and col < C.shape[1]:\n",
        "        sum = 0.0\n",
        "        for k in range(A.shape[1]):\n",
        "            sum += A[row, k] * B[k, col]\n",
        "        C[row, col] = sum\n"
      ],
      "metadata": {
        "id": "wu9btJE0AYzS"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kernel with shared memory"
      ],
      "metadata": {
        "id": "HUJp2TU_A49u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Kernel with shared memory\n",
        "@cuda.jit\n",
        "def matmul_shared_kernel(A, B, C):\n",
        "    sA = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
        "    sB = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
        "    x, y = cuda.grid(2)\n",
        "    tx, ty = cuda.threadIdx.x, cuda.threadIdx.y\n",
        "    if x >= C.shape[0] or y >= C.shape[1]:\n",
        "        return\n",
        "    temp = 0.0\n",
        "    for i in range(int(A.shape[1] / TPB)):\n",
        "        sA[ty, tx] = A[x, ty + i * TPB]\n",
        "        sB[ty, tx] = B[tx + i * TPB, y]\n",
        "        cuda.syncthreads()\n",
        "        for k in range(TPB):\n",
        "            temp += sA[ty, k] * sB[k, tx]\n",
        "        cuda.syncthreads()\n",
        "    C[x, y] = temp\n"
      ],
      "metadata": {
        "id": "ZRCCRaDhA694"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matrix multiplication execution function"
      ],
      "metadata": {
        "id": "GPDGM90LA9Jc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform matrix multiplication\n",
        "def matmul_gpu(A, B, use_shared):\n",
        "    A_device = cuda.to_device(A)\n",
        "    B_device = cuda.to_device(B)\n",
        "    C_device = cuda.device_array((N, N), dtype=np.float32)\n",
        "    blockspergrid = (math.ceil(N / TPB), math.ceil(N / TPB))\n",
        "    start = time.time()\n",
        "    if use_shared:\n",
        "        matmul_shared_kernel[blockspergrid, (TPB, TPB)](A_device, B_device, C_device)\n",
        "    else:\n",
        "        matmul_kernel[blockspergrid, (TPB, TPB)](A_device, B_device, C_device)\n",
        "    cuda.synchronize()\n",
        "    end = time.time()\n",
        "    print(f\"Execution time: {end - start:.4f} seconds\")\n",
        "    return C_device.copy_to_host()\n"
      ],
      "metadata": {
        "id": "56fVx17JAY1K"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate and display result"
      ],
      "metadata": {
        "id": "McTLMR0YA-uz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and display result\n",
        "C = matmul_gpu(A, B, use_shared)\n",
        "print(\"Matrix multiplication result:\\n\", C)\n"
      ],
      "metadata": {
        "id": "6FVL5K-rAY3N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c439f229-e82e-4e75-d630-95f17102cde1"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time: 2.5950 seconds\n",
            "Matrix multiplication result:\n",
            " [[1253.4149 1264.2921 1255.6302 ... 1282.8734 1275.8226 1279.1812]\n",
            " [1234.7328 1253.2761 1233.0634 ... 1264.9348 1271.144  1265.0441]\n",
            " [1241.063  1238.1512 1236.2037 ... 1151.7234 1149.4824 1139.849 ]\n",
            " ...\n",
            " [1253.654  1367.8208 1462.7887 ... 1379.2767 1380.4052 1182.7166]\n",
            " [1266.3993 1369.3339 1474.8586 ... 1403.8734 1468.8204 1175.8052]\n",
            " [1242.7612 1355.1373 1442.8925 ... 1459.5002 1616.5847 1283.6373]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define matrix and tile size"
      ],
      "metadata": {
        "id": "Q8OzRcujBAp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define matrix and tile size\n",
        "N = 10000\n",
        "TILE_DIM = 32\n"
      ],
      "metadata": {
        "id": "bANDRoR9AY5I"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tiled kernel for large matrix multiplication"
      ],
      "metadata": {
        "id": "PoHc-NXaBDFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@cuda.jit\n",
        "def matmul_tiled_kernel(A, B, C):\n",
        "    # Declare shared memory for blocks\n",
        "    tile_A = cuda.shared.array((TILE_DIM, TILE_DIM), dtype=float32)\n",
        "    tile_B = cuda.shared.array((TILE_DIM, TILE_DIM), dtype=float32)\n",
        "\n",
        "    # Thread, block, and tile indices\n",
        "    bx, by = cuda.blockIdx.x, cuda.blockIdx.y\n",
        "    tx, ty = cuda.threadIdx.x, cuda.threadIdx.y\n",
        "    x, y = tx + bx * TILE_DIM, ty + by * TILE_DIM\n",
        "\n",
        "    sum = 0.0\n",
        "    for i in range((N + TILE_DIM - 1) // TILE_DIM):\n",
        "        # Load tiles into shared memory\n",
        "        if i * TILE_DIM + tx < N and y < N:\n",
        "            tile_A[ty, tx] = A[y, i * TILE_DIM + tx]\n",
        "        else:\n",
        "            tile_A[ty, tx] = 0\n",
        "\n",
        "        if i * TILE_DIM + ty < N and x < N:\n",
        "            tile_B[ty, tx] = B[i * TILE_DIM + ty, x]\n",
        "        else:\n",
        "            tile_B[ty, tx] = 0\n",
        "\n",
        "        cuda.syncthreads()  # Synchronize threads in block\n",
        "\n",
        "        # Multiply tiles\n",
        "        for k in range(TILE_DIM):\n",
        "            sum += tile_A[ty, k] * tile_B[k, tx]\n",
        "\n",
        "        cuda.syncthreads()  # Synchronize before loading the next tile\n",
        "\n",
        "    if x < N and y < N:\n",
        "        C[y, x] = sum\n"
      ],
      "metadata": {
        "id": "ZKXDTFr0AY7E"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matrix creation and transfer to GPU for tiled kernel"
      ],
      "metadata": {
        "id": "Ck_tM45tF32K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix creation\n",
        "A = np.random.rand(N, N).astype(np.float32)\n",
        "B = np.random.rand(N, N).astype(np.float32)\n",
        "C = np.zeros((N, N), dtype=np.float32)\n",
        "\n",
        "# Transfer matrices to GPU\n",
        "A_device = cuda.to_device(A)\n",
        "B_device = cuda.to_device(B)\n",
        "C_device = cuda.to_device(C)\n"
      ],
      "metadata": {
        "id": "HcvjW0lZAY89"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configure thread and grid blocks, launch CUDA kernel, and retrieve results"
      ],
      "metadata": {
        "id": "pJAInmInF5dS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure thread and grid blocks\n",
        "threads_per_block = (TILE_DIM, TILE_DIM)\n",
        "blocks_per_grid = (math.ceil(N / TILE_DIM), math.ceil(N / TILE_DIM))\n",
        "\n",
        "# Launch CUDA kernel\n",
        "matmul_tiled_kernel[blocks_per_grid, threads_per_block](A_device, B_device, C_device)\n",
        "\n",
        "# Retrieve results from GPU\n",
        "C = C_device.copy_to_host()\n"
      ],
      "metadata": {
        "id": "GZiPPkRAF69s"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display sample result"
      ],
      "metadata": {
        "id": "0AGC2IVJF93N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display results\n",
        "print(\"Matrix multiplication result (sample):\\n\", C[:5, :5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KN1jexyF-bM",
        "outputId": "a68b5ea4-cc9e-4978-ca3b-4afcba0ad27d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix multiplication result (sample):\n",
            " [[2487.4058 2469.4377 2496.5815 2499.6643 2496.6184]\n",
            " [2517.4097 2467.949  2525.5752 2510.6067 2512.0613]\n",
            " [2494.2    2470.1106 2518.3276 2520.9238 2502.7434]\n",
            " [2497.048  2479.4536 2522.7744 2515.4663 2503.5168]\n",
            " [2480.5332 2437.5642 2499.915  2499.4597 2492.8352]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation function"
      ],
      "metadata": {
        "id": "FFTXZ_tWF_sp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_results(A, B, C):\n",
        "    # Compute matrix product with NumPy for validation\n",
        "    C_numpy = np.dot(A, B)\n",
        "    if np.allclose(C, C_numpy, atol=1e-5):\n",
        "        print(\"Validation successful: GPU and NumPy results are similar.\")\n",
        "    else:\n",
        "        print(\"Validation error: Results differ.\")\n",
        "\n",
        "# Use this function after retrieving C from the GPU\n",
        "validate_results(A, B, C)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oF1OReKeGkw8",
        "outputId": "0ec252f1-64ad-48ff-aecf-ee48c08cae13"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation successful: GPU and NumPy results are similar.\n"
          ]
        }
      ]
    }
  ]
}